---
title: "Speed Comparisons"
jupyter: python3
toc: true
toc-depth: 3
number-sections: true
number-depth: 2
code-fold: true
code-tools: 
    source: false
    toggle: true
---

::: {.callout-note collapse="false"}
## How this guide benefits you

This guide covers speed and performance comparisons using the `polars` backend. 
:::

# Pytimetk Speed Result Summary

| Features/Properties | **polars**  | **pandas** |
|---------------------|------------|----------------------|
| `summarize_by_time()` | üöÄ 13X Faster | üê¢ Standard |
| `augment_rolling()` | üöÄ 10X to 3500X Faster | üê¢ Standard  |
| `augment_expanding()` | üöÄ 2X to 500X Faster | üê¢ Standard |


# About Performance

Beginning in version 0.2.0 of `pytimetk`, we introduced new `polars` engines to many of our functions. This is aimed at leveraging the speed benefits of polars without requiring you (the user) to learn a new data manipulation framework. 

## Key benefits:

1. You can get between 2X and 500X speed boost on many common time series operations
2. You don't need to know how to use `polars` to gain massive speed boosts
3. Simply turn `engine = 'polars'` to get the speed boost. 

## What affects speed?

Many factors can affect speed. Things that are known to slow performance down:

1. Using non-optimized "lambda" functions. Lambda Functions are created at runtime. This process is flexible but extremely inefficient. Where possible use "built-in" or "configurable" functions instead. 
   
2. Not using `polars`. Polars is built on top of Rust, which is a low-level language known for performance and optimized for speed. Using polars usually speeds up computation versus Pandas.





# Speed Tests and Conclusions

Load the packages and datasets needed to replicate the speed tests (Click to Expand):

```{python}
# | eval: true

# Libraries
import pytimetk as tk
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from pytimetk.utils.polars_helpers import pl_quantile
from pytimetk.utils.pandas_helpers import pd_quantile

# Datasets
expedia_df = tk.load_dataset("expedia", parse_dates = ['date_time'])
m4_daily_df = tk.load_dataset("m4_daily", parse_dates = ['date'])

# Plotting utility
def make_time_comparison_plot(title, methods, times, height_spacer=500):
    """
    Create a bar chart comparing execution times of different methods.
    
    Args:
    - title (str): Title for the plot.
    - methods (list of str): Names of the methods being compared.
    - times (list of float): Execution times corresponding to the methods.
    - height_spacer (int, optional): Additional space above the tallest bar. Defaults to 5000.
    
    Returns:
    - None. Displays the plot.
    """
    
    # Calculate how many times slower each method is relative to the fastest method
    min_time = min(times)
    times_slower = [time / min_time for time in times]

    # Create the bar chart
    bars = plt.bar(methods, times, color=['blue', 'red', 'green', 'orange'])

    # Add title and labels
    plt.title(f'{title}: Comparison of Execution Times')
    plt.ylabel('Execution Time (ms)')
    plt.xlabel('Methods')

    # Display the execution times and how many times slower on top of the bars
    for bar, v, multiplier in zip(bars, times, times_slower):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2, height + 50, 
                 f"{v} ms\n{multiplier:.1f}X slower" if multiplier != 1 else f"{v} ms", 
                 ha='center', va='bottom', fontsize=9, 
                 color='black' if multiplier != 1 else 'green')

    # Adjust y-axis limit to make sure all labels fit
    plt.ylim(0, max(times) + height_spacer)

    # Display the plot
    plt.tight_layout()
    return plt
```

## Summarize By Time `summarize_by_time()`

- Polars is 13.1X faster than Pandas


```{python}
# | echo: false

# Data
title = "Summarize by Time"
methods = ['Polars', 'Pandas']
times = [50.8, 668]

make_time_comparison_plot(title, methods, times, height_spacer=500)

```


:::{.panel-tabset groups="bbands-plotly-plotnine"}

## Polars

```{python}
# | eval: false
%%timeit -n 10

df_pytimetk = expedia_df[['site_name', 'date_time', 'cnt', 'is_booking']] \
    .groupby('site_name') \
    .summarize_by_time(
        date_column = 'date_time',
        value_column = ['cnt', 'is_booking'],
        freq = 'W',
        agg_func = ['sum', 'count'],
        engine = 'polars'
    )

# 50.8 ms ¬± 2.45 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
```

## Pandas

```{python}
# | eval: false
%%timeit -n 10

df_pytimetk = expedia_df[['site_name', 'date_time', 'cnt', 'is_booking']] \
    .groupby('site_name') \
    .summarize_by_time(
        date_column = 'date_time',
        value_column = ['cnt', 'is_booking'],
        freq = 'W',
        agg_func = ['sum', 'count'],
        engine = 'pandas'
    )

# 668 ms ¬± 16.5 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
```

:::


## Rolling Calculations `augment_rolling()`

- Polars is 10.8X faster than Pandas
- Polars is 3,517X faster than Pandas with Lambdas


```{python}
# | echo: false
import matplotlib.pyplot as plt

# Data
title = "Augment Rolling"
height_spacer = 5000
methods = ['Polars w/ pl_quantile', 'Pandas w/ pd_quantile', 'Pandas w/ Lambda Quantile']
times = [9.81, 106, 34_500]

make_time_comparison_plot(title, methods, times, height_spacer = 5000)

```



:::{.panel-tabset}

## Polars

Uses `pl_quantile()` configurable function.

``` {python}
# | eval: false
%%timeit

expanded_df = (
    m4_daily_df
        .groupby('id')
        .augment_rolling(
            date_column = 'date', 
            value_column = 'value', 
            window = (1,10),
            window_func = [
                'mean',  # Built-in mean function
                'std',   # Built-in std function
                ('quantile_75', pl_quantile(quantile=0.75)),  # Configurable with all parameters found in polars.Expr.rolling_quantile
            ],
            min_periods = 1,
            engine = 'polars',
        )
)
# 9.81 ms ¬± 116 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)
```

## Pandas

Uses `pd_quantile()` configurable function.

``` {python}
# | eval: false
%%timeit

expanded_df = (
    m4_daily_df
        .groupby('id')
        .augment_rolling(
            date_column = 'date', 
            value_column = 'value', 
            window = (1,10),
            window_func = [
                'mean',  # Built-in mean function
                'std',   # Built-in standard deviation function,
                # ('quantile_75', lambda x: pd.Series(x).quantile(0.75)),  # Custom quantile function
                ('quantile_75', pd_quantile(q=0.75))
            ],
            min_periods = 1,
            engine = 'pandas',  # Utilize pandas for the underlying computations
            show_progress = False,
        )
)

# 106 ms ¬± 2.38 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
```

## Pandas (Lambda)

Uses `lambda x: pd.Series(x).quantile(0.75)`. Lambda functions are extremely inefficient. 

``` {python}
# | eval: false
%%timeit

expanded_df = (
    m4_daily_df
        .groupby('id')
        .augment_rolling(
            date_column = 'date', 
            value_column = 'value', 
            window = (1,10),
            window_func = [
                'mean',  # Built-in mean function
                'std',   # Built-in standard deviation function,
                ('quantile_75', lambda x: pd.Series(x).quantile(0.75)), # lambda slows things down
            ],
            min_periods = 1,
            engine = 'pandas',  
            show_progress = False,
        )
)

# 34.5 s ¬± 236 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)
```

:::

## Augment Expanding `augment_expanding()`

- Polars is 3X faster than Pandas with built-in and configurable functions
- Polars is 515X faster than Pandas with lambda functions

```{python}
# | echo: false
import matplotlib.pyplot as plt

# Data
title = "Augment Expanding"
methods = ['Polars w/ pl_quantile', 'Pandas w/ pd_quantile', 'Pandas w/ Lambda Quantile']
times = [6.95, 20.8, 3580]

make_time_comparison_plot(title, methods, times, 500)
```

:::{.panel-tabset}

## Polars

Uses `pl_quantile()` configurable function.

``` {python}
# | eval: false
%%timeit

expanded_df = (
    m4_daily_df
        .groupby('id')
        .augment_expanding(
            date_column = 'date', 
            value_column = 'value', 
            window_func = [
                'mean',  # Built-in mean function
                'std',   # Built-in std function
                ('quantile_75', pl_quantile(quantile=0.75)),  # Configurable with all parameters found in polars.Expr.rolling_quantile
            ],
            min_periods = 1,
            engine = 'polars',
        )
)
# 6.95 ms ¬± 163 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)
```

## Pandas

Uses `pd_quantile()` configurable function.

``` {python}
# | eval: false
%%timeit

expanded_df = (
    m4_daily_df
        .groupby('id')
        .augment_expanding(
            date_column = 'date', 
            value_column = 'value', 
            window_func = [
                'mean',  # Built-in mean function
                'std',   # Built-in standard deviation function,
                # ('quantile_75', lambda x: pd.Series(x).quantile(0.75)),  # Custom quantile function
                ('quantile_75', pd_quantile(q=0.75))
            ],
            min_periods = 1,
            engine = 'pandas',  # Utilize pandas for the underlying computations
        )
)

# 20.8 ms ¬± 1.51 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
```

## Pandas (Lambda)

Uses `lambda x: pd.Series(x).quantile(0.75)`. Lambda functions are extremely inefficient. 

``` {python}
# | eval: false
%%timeit

expanded_df = (
    m4_daily_df
        .groupby('id')
        .augment_expanding(
            date_column = 'date', 
            value_column = 'value', 
            window_func = [
                'mean',  # Built-in mean function
                'std',   # Built-in standard deviation function,
                ('quantile_75', lambda x: pd.Series(x).quantile(0.75)), # lambda slows things down
            ],
            min_periods = 1,
            engine = 'pandas',  
        )
)

# 3.58 s ¬± 110 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)
```

:::

# More Coming Soon...

We are in the early stages of development. But it's obvious the potential for `pytimetk` now in Python. üêç

- Please [‚≠ê us on GitHub](https://github.com/business-science/pytimetk) (it takes 2-seconds and means a lot). 
- To make requests, please see our [Project Roadmap GH Issue #2](https://github.com/business-science/pytimetk/issues/2). You can make requests there. 
- Want to contribute? [See our contributing guide here.](/contributing.html) 


Certainly! Here's a markdown comparison table and a persuasive introduction for the `pytimetk` homepage:

---

## Introducing pytimetk: Simplifying Time Series Analysis for Everyone

Time series analysis is fundamental in many fields, from business forecasting to scientific research. While the Python ecosystem offers tools like `pandas`, they sometimes can be verbose and not optimized for all operations, especially for complex time-based aggregations and visualizations.

Enter **pytimetk**. Crafted with a blend of ease-of-use and computational efficiency, `pytimetk` significantly simplifies the process of time series manipulation and visualization. By leveraging the `polars` backend, you can experience speed improvements ranging from 3X to a whopping 30X. Let's dive into a comparative analysis.

| Features/Properties | **pytimetk**                  | **pandas (+matplotlib)**               |
|---------------------|-------------------------------|---------------------------------------|
| **Speed**           | üöÄ 3X to 30X Faster            | üê¢ Standard                           |
| **Code Simplicity** | üéâ Concise, readable syntax    | üìú Often verbose                      |
| `summarize_by_time()` | üïê 2 lines, 13.4X faster     | üïê 6 lines, 2 for-loops               |
| `plot_timeseries()`  | üé® 2 lines, no customization  | üé® 16 lines, customization needed    |

As evident from the table:

- `summarize_by_time()` in **pytimetk** is not just about speed; it also simplifies your codebase, converting a 6-line, double for-loop routine in `pandas` into a concise 2-line operation.
  
- Similarly, `plot_timeseries()` dramatically streamlines the plotting process, encapsulating what would typically require 16 lines of `matplotlib` code into a mere 2-line command in **pytimetk**, without sacrificing customization or quality.

Join the revolution in time series analysis. Reduce your code complexity, increase your productivity, and harness the speed that **pytimetk** brings to your workflows.

Explore more at [pytimetk homepage](https://business-science.github.io/pytimetk/).

---

Feel free to modify the content as per your requirements or branding guidelines.